MMO Runtime & Compilation Technical Brief
1. Terminology Normalization

Compilation: The process of translating source code into a lower-level code (for C#, into IL – Intermediate Language – or directly into machine code). Compilation is one step in producing a runnable program
stackoverflow.com
. In Unity’s context, your C# scripts are compiled by the Roslyn compiler into IL assemblies during build
docs.unity3d.com
.

Build vs. Compile: Compiling refers specifically to converting code to executable form (e.g. C# to IL or IL to machine code). Building is a broader process that includes compiling all necessary code and then linking/packaging it into the final application or library
gamedev.net
. In other words, you compile source files, and you build the complete game (compiling code, plus processing assets, linking libraries, etc.). Unity’s “Build” pipeline encompasses compiling scripts, converting IL to native code (if using IL2CPP), bundling assets, and producing the final executable.

IL (Intermediate Language): The CPU-agnostic bytecode produced by compiling .NET languages like C#. In Unity, scripts are first compiled into IL (also called CIL or MSIL) which is then either JIT-compiled at runtime or transformed ahead of time
docs.unity3d.com
. IL code is executed by the .NET/Mono runtime unless it’s ahead-of-time compiled to native code.

JIT (Just-In-Time compilation): A runtime compilation technique where IL code is compiled to machine code on the fly as methods are called. Unity’s Mono backend uses JIT compilation – code is compiled on demand during execution rather than in advance
docs.unity.cn
. This yields faster iteration (short build times) but means the device does some work to compile code at runtime. JIT can introduce slight delays when new code paths execute and is disallowed on certain platforms (like iOS).

AOT (Ahead-Of-Time compilation): Compiling IL code into machine code before running the program. Unity’s IL2CPP backend performs AOT compilation: the entire IL codebase is converted to optimized native binaries at build time
docs.unity.cn
. AOT eliminates JIT runtime overhead and is required on platforms that forbid JIT (iOS, console). It tends to improve performance and startup times at the cost of longer build times and larger binaries
docs.unity3d.com
.

IL2CPP: Unity’s IL (Intermediate Language) to C++ conversion backend. IL2CPP takes your compiled IL assemblies and transpiles them into C++ code, then invokes a native platform compiler to produce a binary
docs.unity3d.com
docs.unity3d.com
. This is an AOT process; IL2CPP-generated builds often run faster and start up quicker than Mono builds, and IL2CPP is the only option on platforms like iOS
docs.unity3d.com
. However, IL2CPP builds have longer compile times and can be harder to debug at the code level.

Managed vs. Native memory: Managed memory refers to memory allocated on the managed heap by the .NET/Mono runtime for C# objects. It’s automatically tracked and collected by the garbage collector
docs.unity3d.com
docs.unity3d.com
. Native memory refers to memory allocated outside the managed heap – for example, Unity engine objects, textures, meshes, and other allocations done in C/C++ side. The garbage collector does not free native allocations
docs.unity3d.com
; those must be released via engine APIs (e.g. Object.Destroy for UnityEngine objects or unloading scenes/assets). In Unity, assets and engine objects reside in native memory, which means you must explicitly destroy or unload them to avoid leaks
docs.unity3d.com
docs.unity3d.com
.

GC vs. Memory Leaks: The garbage collector (GC) automatically frees managed heap objects that are no longer referenced
docs.unity3d.com
. This helps prevent classic memory leaks where a programmer forgets to free memory. However, memory leaks can still happen in managed environments if you inadvertently keep references to objects that are no longer needed. A managed memory leak is typically not a leak in the traditional sense, but rather unintentional object retention (e.g. static lists accumulating data, or events preventing object cleanup) – the GC can only collect objects with no references
docs.unity3d.com
. In contrast, native memory leaks occur when the program fails to release native resources; since GC doesn’t manage native memory, those leaks must be handled by proper API usage (destroying objects, unloading assets). Always distinguish between GC-related pauses (which indicate lots of allocation/collection) and true leaks (ever-growing memory usage due to lingering references or unreleased resources).

Runtime allocation: Any memory allocation that occurs during gameplay (as opposed to during initial load). This includes creating new objects, enlarging collections, or instantiating prefabs at runtime. Excessive runtime allocations are problematic because they consume CPU time and trigger garbage collections
docs.unity3d.com
. Each new operation on the managed heap can generate GC pressure. Best practice is to minimize runtime allocations in performance-critical code, by pre-allocating and reusing objects (object pooling) and using structures that avoid frequent alloc/free patterns. Remember that even small allocations (e.g. string concatenations, boxing a value type) can add up in a hot loop, eventually causing GC spikes.

Long-running process: In the MMO context, this means a server or service intended to run continuously for days, weeks, or more without restart. Long-running processes face challenges like memory fragmentation over time, gradual performance degradation, and the need for robust cleanup. Unity’s GC is non-compacting
medium.com
, so a long-lived server will accumulate fragmented managed heap space unless allocation patterns are stable. Small inefficiencies (like a tiny leak each hour) that are negligible in a short play session can become critical over a week. Thus, code for a long-running MMO server must rigorously avoid any accumulation of garbage or resources – it should be written as if it might run indefinitely. Expect to handle things like resetting or wrapping counters, cleaning up stale data, and periodically verifying that memory and performance metrics remain steady over time (if not, find the cause before it snowballs).

2. Unity C# Compilation Pipeline (Mono vs. IL2CPP)

Unity uses a multi-step compilation pipeline for C# scripts, with distinct build-time and runtime behaviors:

Editor and Build-Time Compilation: When you enter Play Mode or build the project, Unity invokes the Roslyn C# compiler to translate all your C# scripts (and package assemblies) into IL assemblies (DLLs)
docs.unity3d.com
. These managed assemblies contain your game logic in IL form. If you’re using the Mono scripting backend, these DLLs are packaged with the game. If using IL2CPP, Unity will take an extra step of converting these IL assemblies to C++ and then compiling to native code. Unity also applies managed code stripping at build time (especially with IL2CPP) to remove unused code and reduce binary size
docs.unity3d.com
docs.unity.cn
. The result of the build process is either: an IL-dependent package plus a Mono runtime, or a completely native binary with your code baked in (for IL2CPP).

Mono (JIT) Runtime: With the Mono backend, the build includes the IL assemblies and the Mono runtime. When the game runs, Mono will JIT-compile methods from IL to machine code on demand during execution
docs.unity.cn
. Mono’s JIT compilation is fast enough for development (and used in the Editor), but it means a small runtime cost the first time each method runs. Notably, some platforms (iOS, certain consoles) do not allow JITting – hence Mono cannot be used there
docs.unity3d.com
. Mono’s advantage is faster build times and the ability to use reflection and dynamic code generation fully. Its drawback is slightly lower performance at runtime and an outdated garbage collector (Boehm GC) with no generational collection
gamedev.stackexchange.com
gamedev.stackexchange.com
. In practice, Mono is usually used for iterative development and debugging on PC; for final releases, Unity often recommends IL2CPP for better performance
reddit.com
reddit.com
.

IL2CPP (AOT) Build: With IL2CPP selected, Unity performs ahead-of-time compilation of your scripts. After producing the IL DLLs, the IL2CPP step converts all IL code into C++ source files
docs.unity3d.com
docs.unity3d.com
. Then a native platform compiler (platform-specific toolchain) compiles that C++ into machine code, producing an executable or library
docs.unity3d.com
. This means the device at runtime isn’t JIT-compiling your code – it’s already native. IL2CPP builds can yield improved performance and startup times (especially on CPU-bound logic)
docs.unity3d.com
. The trade-offs are longer build times and larger binaries, since all possible code paths are compiled upfront
docs.unity3d.com
docs.unity3d.com
. IL2CPP is mandatory for iOS and useful on consoles; on Android and desktop it’s optional but often used for release builds. Debugging IL2CPP builds can be trickier – call stacks go through generated C++ code, and some managed debugging capabilities are limited. It’s crucial to thoroughly test IL2CPP builds because certain issues (like C++ compiler differences or AOT-specific bugs) can surface only there
medium.com
.

Platform distinctions: Not all platforms support both backends. For example, iOS requires AOT (IL2CPP) because Apple disallows runtime code emission
docs.unity3d.com
. WebGL also requires IL2CPP (it compiles C# to WebAssembly via IL2CPP, since no JIT in web). Universal Windows Platform has its own .NET backend or IL2CPP. On platforms where both are supported (Windows, Linux, Android), Unity uses Mono by default for faster iteration, but you can switch to IL2CPP for final builds
docs.unity.cn
. Always be mindful of platform: e.g., .NET dynamic features or runtime codegen will work in Editor/Mono, but on IL2CPP targets those features are unsupported
docs.unity.cn
.

Compiler optimizations and flags: Unity’s build settings expose a few options that actually affect performance. One is the IL2CPP Code Generation option – Optimize for speed (the default) vs Optimize for size. The speed option includes more aggressive inlining and generates additional native code for performance, at the cost of a longer build and a bigger binary
docs.unity3d.com
. Choosing the size option can shorten build times and reduce binary size by omitting some optimizations, but will slightly hurt runtime performance. Another relevant setting is Managed Stripping Level: higher levels strip out unused managed code more aggressively to reduce build size, but if set too high it can remove code that is only accessed via reflection
docs.unity.cn
. As for the C# compiler, Unity by default compiles in release mode (optimizations on) unless you check “Development Build”, which enables debug symbols and might disable some optimizations. “Development Build” also enables the profiler and some safety checks, which can marginally impact performance. There are no user-tweakable compiler flags beyond these in Unity; Roslyn is configured by Unity internally. For truly performance-critical sections, Unity provides the Burst compiler (an HPC# LLVM-based AOT compiler for Unity’s Job system) – Burst can massively optimize math-heavy code, but it’s an explicit opt-in for certain jobs, not applied to regular MonoBehaviours. In summary, the standard pipeline’s optimizations are mostly around IL2CPP vs Mono choice, stripping level, and whether it’s a development build. Good coding patterns (avoiding virtual call overhead, using structs appropriately, etc.) remain important, as the C# compiler itself does not magically optimize high-level design issues.

3. Dispelling the “Poor Compilation Causes MMO Issues” Myth

It’s a common misconception among less experienced developers that MMO performance or scalability problems can be solved by “compiling the code better” or switching compiler/backends. In reality, compilation method is rarely the bottleneck or root cause of MMO runtime issues. The choice of Mono vs IL2CPP, or any compiler optimizations, can only affect CPU execution speed by some constant factor and binary size – it cannot fix fundamental architectural problems:

Memory Leaks: If your server or client has a memory leak (e.g. objects piling up because you never release or deregister them), using IL2CPP or any fancy compiler won’t help. A leak is a logic issue – the garbage collector can’t reclaim objects still referenced, and native memory won’t free itself without explicit calls. For example, if event handlers aren’t removed properly, objects stay alive forever
stackoverflow.com
, leading to memory bloat. No compiler can detect or resolve that for you; the code must be designed to clean up after itself.

GC Pressure & Spikes: High garbage collection overhead comes from excessive allocations at runtime. This is a byproduct of code patterns (like creating lots of garbage every frame). Whether you JIT or AOT compile the code, those allocations will still happen. An IL2CPP build might execute slightly faster, but if your code allocates huge amounts, you’ll still get GC spikes and frame stutters
medium.com
medium.com
. The solution is to change the code (pool objects, avoid per-frame allocations
medium.com
medium.com
) – not to hope a different compiler will magically eliminate the garbage collector costs.

Scaling Limits (CPU/N^2 issues): Many MMO issues come from algorithmic complexity or poor scaling of network and CPU usage (for instance, doing an O(n²) operation when n players interact, or not partitioning game world updates). These are design issues. A faster compilation (IL2CPP) might give you, say, 20% better raw CPU throughput in the best case – but an O(n²) algorithm will still blow up exponentially with more players
forum.starbasegame.com
forum.starbasegame.com
. In practice, MMO server bottlenecks often lie in things like pathfinding, physics, database I/O, or network bandwidth – none of which are meaningfully improved by compiler optimizations. You need architectural solutions (better algorithms, spatial partitioning, load balancing across servers), not just “better machine code.”

Networking and I/O: Network throughput and latency form a hard limit that compilation can’t fix. A Reddit discussion on MMO server tech noted that the real limiting factor is often network bandwidth/latency, not raw CPU power
reddit.com
. In other words, you can compile the server to the most optimized native code, but it won’t send packets any faster than the network allows. If your MMO is lagging due to sending too much data or slow client connections, addressing that requires protocol and bandwidth optimizations (e.g. culling updates, compression), not flipping a compiler switch.

Runtime Errors and Stability: Some might blame crashes or glitches on the “build” as well. While it’s true that IL2CPP vs Mono can exhibit different bugs, most gameplay bugs or server crashes come from logic errors (null references, race conditions, etc.) or memory issues (like unmanaged memory exhaustion). AOT vs JIT doesn’t change your high-level C# semantics. For example, if you have a null-pointer error or an unchecked overflow, it will occur regardless of compilation method. Similarly, memory fragmentation or floating-point precision accumulation over a long uptime are environment issues unaffected by how code was compiled.

In short, compilation is not a scapegoat for MMO performance problems. It’s vital to refute the idea that “the build is slow” is the cause of poor server tick rates or low FPS. Almost always, the cause lies in the code’s behavior at runtime – which must be optimized through better architecture and coding practices. Compilation choices (Mono vs IL2CPP, etc.) are about squeezing extra performance or meeting platform requirements, not about fixing leaks or bad logic. As one Unity best-practices guide notes, Unity developers must write code with the engine’s GC and limitations in mind
gamedev.stackexchange.com
 – you can’t rely on the compiler to save you from bad code.

4. Runtime Cost Factors in MMO Environments

Running a complex MMO (client or server) incurs various types of costs at runtime. Understanding these categories helps in diagnosing and optimizing performance issues. The main areas of runtime cost are CPU usage, memory usage (and GC), network overhead, and long-uptime degradation. We outline each and distinguish how they manifest on client vs. server:

CPU Load: This is the raw processing power consumed per frame or tick. On the client, CPU is spent on rendering frames (animating, culling, draw calls), running game logic for the local player, physics for nearby objects, AI for local NPCs, and decoding/processing network updates. On the server, CPU is used for the authoritative simulation: processing all players’ inputs, running AI for potentially hundreds of NPCs, physics and collision across the game world, executing game rules (combat calculations, quest logic), and serializing state to send to clients. Inefficient algorithms or lack of batching can spike CPU: e.g., if the server checks every player against every other player for some interaction, that O(n²) loop will chew CPU as n grows
forum.starbasegame.com
. High CPU usage can lead to low tick rates (server can’t keep up with 10 Hz tick) or low FPS on clients. Mitigations include optimizing algorithms (use spatial grids, partition the world), offloading work to background threads or other server nodes, and culling unnecessary calculations. A known scaling problem is entity overload: too many active entities will overload the CPU – the Caelmor design preemptively addresses this via distance-based culling of entities outside a zone of interest. In summary, CPU cost is about per-frame computation; whether on client or server, you must minimize unnecessary work and keep the complexity per tick linear or sub-linear relative to players and objects.

Memory Pressure: This refers to how much RAM is used and how it grows over time. A client typically loads lots of assets (models, textures, sounds) into memory for rich visuals. Memory on clients affects loading times and can cause hitching if the OS starts swapping. A server usually has less in terms of textures/models loaded, but instead holds a vast amount of game state: all connected player objects, NPC states, world geometry or navmesh in memory, caches of database queries, etc. For servers, memory is often the limiting factor for how many players or zones can be hosted on one process. If memory usage climbs continuously, that’s a huge red flag (indicates a leak or uncontrolled data growth). Both managed and native memory are concerns: e.g., a server might inadvertently keep references to old player objects (managed leak), or never unload unused assets like zones that are no longer active (native memory leak). Memory pressure also increases GC frequency – the more objects allocated, the more often GC must run. In Unity, the GC is conservative and non-moving, which can lead to fragmented memory over time
medium.com
. After hours or days, a long-running server might have a large heap with fragmentation gaps that can’t be reused effectively, causing even moderate allocations to trigger heap expansion
gamedev.stackexchange.com
gamedev.stackexchange.com
. Regular memory profiling is needed. On client side, memory pressure can cause frame drops when GC runs or when assets stream in/out. On server side, memory bloat can eventually crash the process or drastically slow it (due to constant GC or OS paging). Thus, both client and server must carefully manage memory: use pooling to reuse objects, destroy/unload assets that are no longer needed, and prefer lightweight data structures for large-scale data. A sound strategy is to treat memory as a budget per player or per zone – e.g., X MB of managed memory per 100 players – and raise an alert if usage exceeds expected bounds (sign of a leak). Ultimately, stability over long uptime requires that memory usage hit a steady-state and not grow unbounded.

Garbage Collection & GC Spikes: While a subset of CPU, GC behavior is crucial enough in Unity to consider separately. GC spikes occur when the garbage collector runs and halts normal execution. In old Unity Mono, this was a stop-the-world collection, very visible if lots of garbage had accumulated (long freeze). Newer Unity uses incremental GC by default, spreading work over frames
medium.com
, but if allocations are too frequent or references too mutate-heavy, the incremental collector can fall behind and revert to a full collection
medium.com
 – resulting in a noticeable hitch. On the client, a GC spike typically manifests as a sudden frame drop or stutter (e.g. a freeze for 50+ ms when a big collection happens). On servers, a GC pause could delay the tick loop, potentially causing lag for all players or timing issues in the simulation. A telling sign of GC issues is seeing frequent GC.Alloc entries in the Unity Profiler or log spikes in frame time coinciding with collections. Causes include: generating garbage every frame (strings, temporary objects, LINQ usage allocating, etc.), or big bursts of allocation (loading many assets or spawning many objects at once). MMOs are especially prone to this during peak events (e.g. 50 players enter a new area simultaneously, triggering lots of instantiations). The solution is to reduce garbage production: reuse objects via pooling, avoid per-frame allocations like the plague
medium.com
medium.com
, and consider ArrayPool<T> or preallocated buffers for large arrays. Use tools: Unity’s Profiler and Memory Profiler can show where allocations are coming from. Also, Unity’s API provides GarbageCollector.GCMode – some projects even disable GC entirely during gameplay and periodically enable it at safe times (risky but effective for avoiding spikes
docs.unity.cn
docs.unity.cn
). In summary, GC cost is about timing – keep allocations so low that the collector never causes a noticeable blip. Both client and server code must be written with Unity’s GC limitations in mind (no generational GC
gamedev.stackexchange.com
, no compaction): it is one of Unity’s notorious pain points that good MMO developers work around by design
gamedev.stackexchange.com
.

Network Overhead: Networking is the lifeblood of an MMO, and it carries a CPU cost (for serialization, encryption, compression) as well as bandwidth cost. On the server, network overhead scales with the number of clients: the server must send updates to each client, and possibly receive inputs from each. The amount of data and frequency of sends can become enormous. A single player might only send, say, 5 KB/sec of input data, but the server might be sending 5 KB/sec to each of 200 players = 1 MB/sec outbound. The work to construct those network messages (serializing object states, delta compressing, etc.) can consume a lot of CPU. Additionally, the sheer bandwidth requirement might exceed what’s available, causing latency or packet loss. A Reddit comment on MMO servers pointed out that beyond CPU, network throughput is often the bottleneck – you simply can’t push infinite updates to all players
reddit.com
. That’s why MMOs use techniques like interest management (only send relevant data to each client) and rate limiting. On the client side, network overhead is usually less about CPU (though decoding many messages can spike CPU on client too) and more about latency and bandwidth constraints of the user’s connection. From a runtime perspective, both client and server need to optimize network usage: coalesce messages, compress where feasible, drop lower-priority updates if bandwidth is constrained. If network traffic is not controlled, it leads to lag and server frame drops (if sockets flood the thread). Keep an eye on the “messages per second” and bytes per second metrics; they should scale roughly linearly with player count. If you find an exponential growth (each new player causes disproportionately more traffic), that’s an architectural red flag (see the N^2 problem)
forum.starbasegame.com
. In short, network overhead is a scaling cost – as players increase, it can dominate. Plan for efficient protocols and consider that beyond a certain player count, you must shard or partition the world to keep network load manageable.

Long-Uptime Failure Points: An MMO server (and even a continuously running client) must handle running for very long periods. Certain issues only emerge over time. For example, memory fragmentation: Unity’s GC doesn’t compact memory, so after hours of allocate/deallocate churn, the managed heap may become fragmented such that even though you freed a lot, you can’t get a large contiguous block for the next big allocation
medium.com
gamedev.stackexchange.com
. This can trigger frequent heap expansions and eventually memory exhaustion. Another long-term issue is floating-point drift or precision loss in long-running calculations (though less of an issue at typical tick rates/durations, it can happen in subtle ways). Resource handle leaks are another: e.g., failing to close file handles or network sockets can eventually exhaust OS resources after many hours. Slow leaks in game state – e.g., a list of “recent chat messages” that grows without limit, or leftover data from disconnected players not fully cleaned up – will eventually cause a crash after days. Even CPU load can degrade over time if some algorithms have worst-case behaviors that only show up with large accumulated data (pathfinding in an increasingly populated world, etc.). Therefore, runtime cost isn’t just instantaneous metrics, but also how the system behaves over extended time. A robust MMO service needs monitoring for things like memory usage over time, tick duration over time, etc., and it must have cleanup tasks: e.g., resetting certain caches daily, unloading and reloading scenes to free memory, or at least the capability for a graceful restart during off-hours. On the client, long uptime is less critical (few players keep a client running for more than several hours), but memory leaks can still crash a client if they go unaddressed (hence the common advice: restart the game every few hours if you notice slowdowns
reddit.com
). On the server, you ideally never want to restart (to avoid kicking players), so it must sustain long uptimes. Design patterns like periodic self-health checks, watchdogs for increasing memory, and redundancy (so one server can restart while others carry load) are wise. Treat any trend in resource usage as a bug: in a steady-state MMO server, CPU, memory, and network should reach a plateau for a given player load. If any keep creeping up, find out why (it’s usually a leak or accumulating backlog).

Client vs Server: In summary, the client’s runtime costs center on frame-rate (CPU/GPU per frame) and smooth gameplay experience, whereas the server’s costs center on tick-rate and scalability with player count. The client is bounded by the user’s device capabilities and needs to maintain ~60 FPS; it deals with short sessions but must handle spikes (like entering a crowded town). The server runs indefinitely and must handle aggregate load; it doesn’t render graphics but might simulate thousands of entities across many players. Both share challenges in memory and GC, but for a server those challenges are magnified by longevity and concurrency. One must separately optimize both: e.g., on client, you might be OK with a small GC spike if it avoids loading screens, but on a server you’d avoid that at all costs. Ultimately, robust MMO design means keeping all these costs in check through disciplined coding and system design, so neither clients nor servers tip over under load.

5. Ruleset for MMO Runtime Architecture Design (Must & Must Nots)

To ensure a stable and scalable MMO, certain design rules must be followed in the code and architecture. These rules enforce proper object lifecycle management, event handling, memory usage, and update loop behavior. The following are non-negotiable guidelines, phrased as “must” or “must not” requirements:

Object Lifecycle Management: Every game object or entity with a dynamic lifecycle must be properly destroyed or recycled when no longer needed. You must not allow orphaned objects to persist indefinitely. For example, if a player logs out, all server-side objects associated with that player (avatar, inventory, AI agents, etc.) must be cleaned up promptly. If using Unity, call Destroy() on GameObjects that have been removed from play to free their native memory
docs.unity3d.com
. Prefer object pooling for frequently used objects – e.g., network projectile objects should be reused rather than constantly spawned and destroyed – but even pooled objects should be released (returned to pool) when appropriate. No object should be immortal unless it’s truly global and intended to live for the lifetime of the process (and such cases should be extremely limited).

Event Subscription and Handlers: Objects must unsubscribe from events when they are destroyed or when the subscription is no longer relevant. Failing to remove event handlers is a classic memory leak in C# – the event publisher holds a reference to the subscriber, preventing garbage collection
stackoverflow.com
. Thus, every += to an event must have a corresponding -= at the appropriate time (e.g., in Unity, in OnDestroy or when disabling a feature). This rule also means no using global static events without a robust mechanism to clear subscribers. Must not leave delegates or UnityEvents hanging with listeners to objects that have gone out of scope. In short, any object that subscribes to an event must either unsubscribe or be guaranteed to die at the same time as the publisher. This prevents lingering references and potential memory leaks or unintended callbacks.

Pooling and Allocation: You must use object pooling for any object or data that is created and destroyed frequently (per frame or per tick). For instance, if your game spawns projectiles, AI agents, or FX frequently, implement a pool to reuse these objects instead of constantly allocating new ones
docs.unity3d.com
. Similarly, reuse data structures: use Clear() on lists rather than creating new lists every time, use ArrayPool<T> for large arrays or byte buffers, etc. Conversely, you must not allocate memory inside tight loops or tick updates when it can be prepared ahead of time. Avoid runtime new operations during gameplay for routine tasks – preallocate needed objects during load or initialization. The goal is zero-GC frames during normal play. Do not rely on the garbage collector to manage lots of short-lived objects; instead structure your code to reuse and recycle. Pooling adds complexity, but in an MMO context it is absolutely required for things like network message objects, database query objects, game entity objects, etc., to prevent memory churn.

Tick Loop (Update) Behavior: The server authoritative simulation must run on a fixed tick interval (e.g. 10 Hz as in our design). All gameplay logic updates (movement, combat, AI, etc.) should be tied into this tick and complete within one tick’s time budget. You must not write server logic that assumes a variable frame rate or that tries to run as fast as possible – always adhere to the fixed tick, which keeps the simulation deterministic and in sync. Within the tick loop, must not perform long blocking operations. Any expensive task (pathfinding, large database access) should be broken into smaller steps or moved to background threads such that each tick’s work stays consistent. The tick loop must also be robust against timing issues: e.g., if one tick runs long, the system should catch up or at least not spiral out of control (use time buffers or tick catch-up logic). On the client side, the rendering Update loop must similarly avoid spikes – never put huge workloads in a single frame. Distribute work over multiple frames or time-slice if needed (for instance, processing 1000 spawned objects over 10 frames instead of all in one frame). The guiding principle: each tick/frame’s workload should be as uniform and predictable as possible; avoid designs where a certain rare event causes a massive spike.

No Main-Thread Blocking I/O: You must not perform file I/O, network blocking calls, or any waiting on locks on the main thread (or Unity’s update thread). MMO code often needs to save data or fetch from databases – this must be done asynchronously or on worker threads so that the main loop (frame or tick) never stalls waiting for I/O. This rule means do not, for example, call a database query synchronously during a tick; instead, issue async requests and handle the result on a subsequent tick. Disk writes (saving player inventories, etc.) should be queued and done off-thread, or at least at end-of-cycle points where some delay is acceptable. The server tick thread (or Unity main thread) should be considered sacrosanct for compute only; any operation that could block unpredictably must be offloaded.

Deterministic Object Lifecycle: Objects that move between systems (e.g., spawned in one subsystem and destroyed in another) must have a clear ownership and lifecycle policy. For example, if a monster dies, decide whether the CombatSystem or the World/SpawnSystem is responsible for removing it. Implement explicit destroy messages or flags rather than relying on GC to eventually collect things. In an MMO server, a stray object not cleaned up can accumulate and cause issues hours later. Therefore, every allocation of a gameplay object should have a corresponding destruction path that is triggered when appropriate (health reaches 0, player logs out, etc.). You must not create objects that “float” without ownership or clear responsibility for cleanup.

Memory Limit Management: Design with memory limits in mind. You must set budgets (for example: each zone can use up to X MB of managed memory, Y MB of textures, etc.) and enforce them. If a data structure grows (like a list of active NPCs), have safeguards – e.g., despawn or stop spawning if limits are hit. You must not allow unbounded growth of collections. This includes caches: any caching mechanism should have a max size or eviction policy. For instance, if you cache player data or zone data in memory, decide how and when to unload or evict least-used entries. The absence of memory limits is a recipe for eventually crashing the server (it will run out of memory). Thus, every growing list, map, or pool should either be bounded or periodically prunable.

Event and Callback Management: Aside from unsubscribing events (covered above), you must also guard against unregulated event invocation. For example, if you have an event for “OnPlayerEnterZone” that potentially notifies many systems, ensure that those systems complete their work quickly and do not cascade something that slows down the tick too much. Avoid infinite or long event chains. Also, must not use recursive or uncontrolled events (e.g., events that trigger events in a loop) as they can be hard to manage and can blow the stack or create unpredictable performance. Keep event handler execution time minimal or shift heavy work out of the immediate event call.

Use Threading and Async carefully: On a server, you likely have multi-threading for networking, world streaming, etc. The rule here is you must ensure thread safety and avoid concurrency pitfalls. Shared data structures must have proper locking or be lock-free. You must not read/modify Unity game objects off the main thread (Unity is generally not thread-safe except for its DOTS/ECS data or custom data structures). Instead, use thread-safe structures to exchange data (producer/consumer queues, etc.). If using async/await for I/O tasks, make sure to capture context appropriately or to handle results back on the main thread. Essentially, background threads are great for offloading work, but all gameplay state modifications must ultimately funnel through the main simulation thread in a coordinated manner to avoid race conditions.

Regular Validation and Cleanup: The architecture must include routine validation of the game world state. For example, you must periodically verify that there are no “stuck” entities (objects that should have been removed but weren’t). Implement diagnostic commands or automated checks to enumerate active objects, total memory, etc., to catch anomalies (like 10000 projectiles still in memory when there should only be 100). If any such anomaly is detected, it’s better to proactively clean it or at least log it loudly. You must not assume the absence of bugs – always code defensively with assertions or checks that can catch if something hasn’t been cleaned up or if something is taking too long. In an MMO, one small leak can become a gigantic problem when multiplied by hours and player count, so aggressive monitoring and cleanup is mandatory.

Each of these rules ensures that the MMO remains maintainable under load. They enforce discipline: releasing resources, controlling update flow, and preventing runaway behaviors. In practice, these “musts” and “must nots” should be baked into code reviews and automated analysis – any violation (like allocating in a hot loop, or forgetting to unsubscribe an event) is a serious bug. Adhering to these rules is necessary to meet the strict performance and stability demands of an MMO runtime.

6. When Compilation Choices Matter (IL2CPP vs. Mono, AOT vs. JIT Scenarios)

While compilation isn’t a silver bullet for performance, there are specific scenarios where the choice of scripting backend or compilation method does matter for an MMO project:

Platform Requirements: The most clear-cut case is when the platform dictates the choice. If you target iOS or certain consoles, you must use IL2CPP (AOT) because those platforms forbid JIT compilation
docs.unity3d.com
. In such cases, the decision is made for you – Mono isn’t even an option in production on iOS. Conversely, some platforms (Windows, Linux desktop) support both; during development you might use Mono for faster playmode iteration, then switch to IL2CPP for the shipped build. Just be aware of platform-specific differences; for example, .NET’s dynamic code generation (Reflection.Emit, etc.) works on Mono but will not work under IL2CPP/AOT
docs.unity.cn
. If your code or third-party libraries rely on emitting code at runtime, you’ll need to refactor those (e.g., switch to expression trees or pre-generated code paths) to run on IL2CPP.

Performance-Critical Code: If your MMO has sections of code that are extremely performance-sensitive (for instance, complex math or encryption algorithms running thousands of times per second), IL2CPP can provide a speed boost. IL2CPP-generated native code is compiled with a modern C++ compiler and can be more optimized than what Mono’s JIT produces
reddit.com
. In some internal tests, IL2CPP builds have shown improved CPU performance, especially on mobile CPUs where ahead-of-time optimizations like inlining and improved code generation make a difference. That said, the difference is not usually more than, say, 10-30% in script performance for typical game logic (with exceptions for very math-heavy code where Burst might be a better solution anyway). On the server side, if you need every ounce of CPU and you can afford the slightly more complex debugging, using IL2CPP for the server build could increase throughput (more NPC AI per frame, etc.). Also, IL2CPP has an edge in startup time and GC performance consistency. Unity’s IL2CPP uses the same GC, but some users report that IL2CPP’s pattern of allocation can lead to slightly fewer long pauses (this can vary).

Memory Usage Differences: The managed-to-native transition can also have memory implications. IL2CPP might produce a larger base memory footprint (due to the binary including all code), but it sometimes also has a smaller runtime managed heap, since more data can end up in native structures. For example, IL2CPP can convert some managed metadata into native, potentially reducing managed overhead. On the other hand, IL2CPP can have higher transient memory usage (because of generating garbage during conversion of big arrays of objects, etc., depending on Unity’s implementation). If you encounter a scenario where Mono vs IL2CPP shows divergent memory behavior, analyze it: one Unity developer noted that memory usage can differ, and even that some things might be slower under IL2CPP in edge cases (e.g., certain thread sync primitives might have overhead in IL2CPP)
github.com
. These are low-level details – generally, IL2CPP’s memory usage is fine, but if you’re pushing the limits, test both and see if one gives an advantage in GC frequency or heap size. Typically, IL2CPP’s lack of JIT means no JIT data structures or emitted code in memory, which is a slight savings. However, IL2CPP cannot take advantage of potential runtime optimizations that a JIT might do for long-running processes (like dynamic recompilation) – though Unity’s Mono JIT is not very advanced in that regard, so this is mostly theoretical.

Debugging and Development Workflow: During active development of the MMO, you might choose Mono in the editor and for quick testing builds because compile/deploy is much faster without the IL2CPP conversion step
discussions.unity.com
. This is valid – but you need to frequently test the IL2CPP build as well. Code that runs under Mono might reveal issues only when AOT-compiled. For example, IL2CPP might throw an exception for an unsupported runtime feature (like trying to use System.Reflection.Emit or runtime generation of generic types that haven’t been explicitly used – AOT can’t compile those on the fly). Or you might hit differences in floating point precision or library behavior. Therefore, one scenario where compilation choice matters is when switching late in development: it’s risky to develop 100% on Mono then only do IL2CPP at the end. We strongly advise performing regular full IL2CPP builds throughout development to catch any IL2CPP-specific issues early (differences in memory, performance, or outright crashes). As a Q&A in a guide noted, switching to IL2CPP only at the final build can introduce surprises and requires thorough testing
medium.com
medium.com
.

Client vs Server builds: If your MMO uses Unity on both client and server, you might make different choices. Perhaps the server runs on Linux x64, where Mono vs IL2CPP is a choice. For a server, raw performance and long-term stability is king, so IL2CPP is attractive for the production server build. But you must consider deployment: IL2CPP on Linux will generate a binary – you need the right toolchain and it’s a less usual path than Mono, but it’s supported. Mono on server could be easier for hotfixing (in theory, you could swap assemblies without rebuilding the whole binary, though Unity doesn’t officially support dynamic assembly loading in production builds). Generally, if using Unity as a server, IL2CPP is recommended for the final build to get performance and to avoid JIT-related hiccups (and it makes cheating via disassembly a bit harder as well). On the client, you’ll use IL2CPP for platforms that need it (iOS, etc.). On PC clients, Mono vs IL2CPP can impact modding: Mono builds are easier to mod (since DLLs are accessible IL), while IL2CPP builds are harder to hook into
reddit.com
reddit.com
. If your project values mod support on PC, you might consider shipping Mono on that platform (some studios do, to allow mods via C# mods). But the trend, and Unity’s own guidance, is to use IL2CPP for shipping builds wherever possible for performance and security
reddit.com
medium.com
. It’s a trade-off to be weighed per platform.

AOT vs JIT code paths: Be mindful that some .NET APIs behave differently with AOT. For instance, serialization systems or dependency injection frameworks often use reflection and may generate code at runtime. Under IL2CPP, anything that is only accessed via reflection and not referenced directly can be stripped, causing runtime errors unless you use link.xml or PreserveAttribute. This is a scenario where compilation choice matters: you must adjust your code or link settings for IL2CPP builds to include those indirectly referenced classes. Another example: implementing a scripting system where users write C# scripts that are compiled at runtime – this is impossible under IL2CPP since there’s no JIT. You’d need an alternative (interpreted script or precompile the scripts). So, decide early if your design involves runtime code compilation; if yes, Mono might be required on platform (or more likely, change the design to avoid runtime compilation).

In summary, use IL2CPP for final releases on all platforms unless you have a specific reason not to. The reasons not to might include needing rapid iteration or modability for PC builds – but even then, weigh that against the performance and security benefits. IL2CPP offers superior performance in many cases and is mandatory on key platforms, so it’s the de-facto choice for any serious MMO deployment. Mono remains invaluable for fast edit-play iterations and debugging (faster build, full support for dynamic inspection). Many teams iterate with Mono in editor, and use IL2CPP in continuous integration to test actual build performance. Always test both pathways. The scenarios where it truly “matters” are when you have to meet a platform requirement, squeeze out extra server performance, or accommodate/dodge a feature (like modding or dynamic code) that one backend handles differently. Make these decisions explicitly and document them in the technical design – e.g., “Server will use IL2CPP – test weekly” or “Mod-support build (PC) will remain Mono – accept perf cost”.

7. Guardrail Instructions for Codex (Enforcement Rules)

When using an AI coding assistant (Codex) to generate or assist with MMO code, we need strict guardrails to ensure the output code adheres to the best practices and rules outlined. The following are mandatory enforcement rules that must be given to Codex. All are phrased as direct instructions (imperatives) to the code generator, focusing on cleanup patterns, avoiding GC-heavy constructs, memory safety, and required annotations or structures. These rules aim to make any AI-generated code MMO-ready and prevent common pitfalls:

Ensure Deterministic Cleanup: Codex must always generate code that includes proper cleanup for any resources or subscriptions it creates. For example, if Codex produces a class that registers an event, it must also produce an OnDestroy or disposal pattern to unregister the event
stackoverflow.com
. If it opens a file or network connection, it must close/dispose it. No generated code should leave hanging subscriptions, open file handles, or undeleted Unity objects. This may involve using using statements, implementing IDisposable, or hooking into Unity lifecycle methods appropriately. The assistant should favor deterministic cleanup (dispose patterns) over relying on the garbage collector’s finalizer (which is non-deterministic and not guaranteed to run in a timely manner).

No Per-Frame/Per-Tick Garbage: Codex must not introduce code that generates garbage every frame or tick unless absolutely unavoidable. This means avoid using operations that allocate memory in hot paths: e.g., do not use string.Concat or String.Format with value types in an Update loop (which causes boxing)
medium.com
; do not instantiate new objects or arrays inside frequently called methods. Instead, the code should reuse objects (use object pools or static buffers). For instance, if generating code to send network messages, Codex should employ a reusable packet object or a preallocated byte buffer rather than allocating a new one each time. The assistant should avoid LINQ in hot code (LINQ allocates garbage). It should avoid creating closure allocations in lambdas inside frequently called methods. Essentially, any pattern known to produce GC allocations (strings, boxing, new allocs, linq, foreach on containers causing enumerator allocations, etc.) in core loops is forbidden. If a temporary object is needed, the code should preferably take it from a cache or pool. Codex should err on the side of explicit, allocation-free logic.

Use Object Pooling Patterns: Codex must use object pooling for ephemeral objects. If generating spawn logic or factory methods for bullets, NPCs, etc., it should show a pooling approach (e.g., a pool class with Get/Release methods) rather than naive Instantiation every time
docs.unity3d.com
. If the prompt was to create, say, a projectile system, the answer should include a pool of projectile objects. This also extends to data structures: for example, using Queue<T> or custom buffers that are cleared and reused instead of new List allocations each time. The guardrail is to default to pooling whenever a new object would be created frequently. If Codex produces any code that does allocate frequently (maybe because the user explicitly asks), it should at least flag it with a comment warning (e.g., “// WARNING: this allocates every frame, consider object pooling”) to ensure human developers are alerted.

Memory-Safe and Bounds-Checked: Codex must enforce memory safety best practices. In C#, this means generally avoiding unsafe code unless explicitly required. The assistant should not produce unsafe blocks or raw pointer manipulation unless the prompt is specifically about that and the usage is justified. Also, Codex should encourage usage of bounds-checked operations: e.g., when accessing arrays or lists, if there’s any uncertainty of bounds, it should include a check or guard condition. For instance, if iterating through players, and removing within the loop, Codex should iterate backward or otherwise guard against index issues. While C# prevents a lot of memory corruption by design, things like using NativeCollections in Unity (NativeArray, etc.) require disposing; Codex should ensure any NativeArray, NativeList, etc., is disposed properly to avoid native memory leaks
docs.unity3d.com
. Another aspect: Codex must not use Resources.Load or similar in a tight loop (which would load assets repeatedly and eat memory); it should load once and reuse references. Any risky operation that could lead to uncontrolled memory usage should be accompanied by safeguards (e.g., if generating code for a cache, include a max size and eviction).

Mandatory Annotations and Attributes: Codex must include important annotations that improve performance or clarity when applicable. For Unity, this means: use [SerializeField] for private fields that need to be set in Inspector (instead of making them public). Use [NonSerialized] for fields that should not be serialized (especially events or delegates, which Unity can’t serialize anyway but to avoid warning). If generating async server code, use [MethodImpl(MethodImplOptions.AggressiveInlining)] only if there is a proven hotspot – don’t randomly sprinkle it, but do mention it if the method is trivial and called extremely often (though this is an edge case). If using Burst (Jobs), ensure [BurstCompile] is added to job structs and any static methods used by Burst are marked appropriately. In general, Codex should know to mark things like singletons with [RuntimeInitializeOnLoadMethod] if needed, use [Tooltip] or [Header] for inspector clarity (for designers, less about performance). It should apply [ThreadStatic] or concurrency annotations if the code pattern calls for thread-local storage. These annotations help with correctness and performance. So, for guardrails: if a certain annotation is known to be required (like [Preserve] to keep a method from stripping if it’s only used via reflection), Codex must include it in the generated code when relevant.

Enforce Profiling Awareness: Codex must assume the code will be profiled and should assist in that. This means two things: (1) Write code in a profile-friendly way – e.g., splitting heavy work over multiple frames will show up clearly in the Unity Profiler timeline; that’s good. (2) Instrumentation: Codex could insert comments or even profiler markers (Unity’s Profiler.BeginSample) to mark sections of code. While not always necessary, if generating a complex tick loop, adding Profiler.BeginSample("XYZ") and EndSample is a good practice. At minimum, Codex should generate code that is easy to trace in profiling – e.g., separate concerns into separate methods (which can appear by name in profiler) rather than one monolithic method. Also, ensure job names or thread names are set if using jobs/threads for clarity in analysis. Essentially, always consider how a developer will verify the performance – code that hides what it’s doing is discouraged. This guardrail ensures that the AI’s code is transparent about its cost.

No Forbidden APIs / Behaviors: Codex must avoid Unity or C# features known to be problematic in an MMO context. For example: do not use GameObject.Find or Object.FindObjectOfType every frame – those are extremely slow at scale (linear search through scene). Do not use SendMessage or InvokeRepeating as they are reflection-based or string-based and inefficient. Avoid OnGUI for game logic (old IMGUI system not suited for runtime except dev tools). Do not use Thread.Sleep in server code (or anywhere – it blocks threads and is almost never what you want in Unity). Do not use busy-waits. Essentially, any anti-pattern known in Unity or server development should be off-limits. Another one: do not use System.GC.Collect() arbitrarily – forcing GC can cause hitch; it’s only acceptable in controlled situations. Codex should not suggest its use unless the user specifically is doing memory debug. Also, avoid allocating large contiguous arrays in one go on the main thread if not needed – e.g., don’t do a 100k size array init in a frame, better to lazy load or chunk it. These are not always black-and-white, but as a guardrail, the AI should prefer safe, proven patterns over “shortcuts” that are known bad at scale.

Thread and Async Safety: If Codex generates code involving threads or async tasks (likely in server code), it must enforce thread-safe practices. For example, if it uses a ConcurrentDictionary or ConcurrentQueue for thread communication, that’s good. If not, it must wrap accesses in locks and clearly delineate what data is protected. It must not share Unity objects across threads (e.g., never pass a GameObject or MonoBehaviour to another thread). It should use thread-safe collections or immutable snapshots of data to pass to background tasks. And it should comment on any assumptions, e.g., “// This method is called from a background thread; be careful to use thread-safe operations.” Also, with async/await, ensure to .ConfigureAwait(false) on truly background awaits if context capture isn’t needed. This level of detail might be advanced, but as a guardrail, we want the AI to produce code that won’t break in subtle ways under concurrency.

Memory usage annotations: The AI should leverage any attributes or patterns that help with memory layout if relevant. E.g., using [StructLayout(LayoutKind.Sequential)] or [FieldOffset] for explicit layouts if interfacing with native. Or using fixed keyword in structs for fixed-size buffers if it’s a scenario like network packets (to avoid separate allocations). The key is to control memory. Codex shouldn’t make big objects when a struct would do (especially for value types that get reused heavily). So one rule: prefer struct over class for simple data containers that are frequently created, to avoid GC (but careful: large structs on the stack can also be an issue, so keep them small). If a struct exceeds, say, 16 bytes, weigh the cost; the AI might not “know” that, but general guidance. Also, if using collections, it should initialize them with capacity if size is known (e.g., new List<T>(100) if we roughly expect 100 elements, to avoid resizes). These micro-optimizations add up in an MMO.

In essence, these guardrail instructions tell Codex: generate code as if a seasoned MMO engineer were watching over your shoulder, ensuring efficiency and safety. Any code suggestion violating these (like leaving an event subscribed, or doing heavy allocs) should be automatically considered incorrect. By enforcing these, we ensure the AI’s contributions align with the project’s stringent performance and reliability needs.

8. MMO Scalability & Safety Red Flags (Anti-Patterns to Avoid)

When reviewing MMO code or architecture, there are several red flags – patterns that often lead to scalability or stability problems. These are the “smell tests” that experienced developers and code reviewers use to catch issues before they manifest in production. Here we categorize common anti-patterns and hazards:

Unbounded Growth (Memory or Collections): Any data structure that grows without limits is a red flag. For example, a server that keeps an ever-growing list of “dead entities” or logs or cached queries with no eviction will eventually run out of memory. If you see a List or Dictionary that is never trimmed or cleared, question it. Common pitfall: not removing players or entities from global collections on disconnect – causing an effective memory leak. Another is accumulating statistics or history forever. In Unity, a subtle case is not destroying game objects (or ScriptableObjects) that are dynamically created – they remain in memory. Red flag: any constructor or spawn method with no corresponding destruction logic implies potential unbounded growth.

No Interest Management (N^2 Network Traffic): As discussed, if every entity’s update is sent to every player, network traffic scales O(n²) with player count – which breaks at scale
forum.starbasegame.com
. If you find a design where the server loops over all players for each player’s action (“for each player, send this to all others”), that’s a huge red flag. The code should instead send updates only to relevant players (those in the same area, party, etc.). Lack of interest management will kill server performance quickly or force artificially low player limits. A telltale sign is code in an update like for each player in players: for each otherPlayer in players: send update – this nested loop is the hallmark of the N² bug. Proper design partitions players (regions, instancing, etc.). So, seeing no spatial partition or no region filtering in an MMO server’s update loop is a serious structural risk.

Excessive Garbage Creation (GC “bombs”): A GC bomb refers to code that unpredictably allocates a massive amount of memory at once, causing a major GC collection or memory spike. For instance, deserializing a huge chunk of data into objects every few minutes without incremental processing, or spawning thousands of objects in one frame. If the profiler or logs ever show a single frame/tick allocating tens of MB of garbage, that’s a red flag
stackoverflow.com
. Examples: using JSON.NET to deserialize a large blob on the main thread (will allocate tons of small objects), or loading an entire zone worth of game objects in one go. The anti-pattern is not splitting work. Also, usage of APIs like Array.Resize frequently can lead to big allocs. Red flag: big memory spikes or periodic hitching likely tied to allocations. The presence of frequent GC.Collect calls in code is also a red flag (it means someone tried to band-aid over GC bombs by forcing collection – usually a sign of underlying allocation issues).

Long Reference Chains / Retained References: Reference chain hazards occur when object A references B, B references C, etc., forming a long chain that unintentionally keeps objects alive. In Unity, a notorious scenario is static managers referencing objects that hold other resources. For example, a static GameManager has a reference to Player which has references to Inventory, which references Items, which reference assets (textures, etc.). Even if you think you unloaded the scene, those assets might still be in memory because the chain via GameManager still exists. A concrete case from a memory guide: a ScriptableObject referenced a Mesh that wasn’t used in the scene, but because a global object still referenced that ScriptableObject, the mesh never unloaded
theknightsofu.com
theknightsofu.com
. Red flag: global or singleton objects that store large hierarchies of other objects without clear release points. Also, events can cause this: object A subscribes to static event, static event lives forever => object A never dies (reference chain from static). So watch for static collections of gameplay objects that are never cleared, or caching of entities in managers that persists beyond their life. Tools like memory profilers can show reference chains; if you see unexpectedly that a supposedly destroyed object is still referenced from some manager, that’s a chain hazard. We must design clear ownership: e.g., when a zone unloads, ensure all its objects and references are dropped. Circular references (A->B, B->A) are fine for GC (it collects them if no external ref), but long chains anchored in static singletons are not fine.

Tick Rate Dependent on Load (Frame/Tick time scaling badly): If adding more entities or players linearly (or worse, exponentially) increases the frame processing time, that’s a red flag for scalability. You might spot this by testing: 10 players -> 5ms tick, 50 players -> 50ms tick, 100 players -> 200ms tick. It indicates some loop or algorithm isn’t scaling linearly or some n² or nm interaction is happening. Red flag in code: algorithms that are O(n²) or O(nm) across subsystems. Example: checking every player against every NPC for aggro range – that’s n*m and will blow up if both populations grow. Use spatial hashing or partitioning instead. Another example: physics with no broad-phase partition – if every object checks collision with every other, it won’t scale. So any double nested loops over large sets should be re-examined. Modern engines handle a lot of this internally, but if your code is doing similar, it’s a risk. Non-linear scaling behavior is often an architecture problem that requires redesign (sharding, partition, or algorithmic improvement)
forum.starbasegame.com
forum.starbasegame.com
.

Single Threaded Bottleneck with No Offloading: If the server code is entirely single-threaded and CPU usage is maxing one core while others idle, that’s a design red flag. Modern MMO servers often use multi-threading or distributed systems to handle more load. Unity by default is largely single-threaded for gameplay code (though you can use DOTS Jobs or offload some tasks). If our server is stuck at, say, 100% on one core at 200 players, that’s a ceiling. Red flag in code would be a single monolithic update loop doing everything, and no utilization of background threads for things like networking or database I/O. It may be okay initially, but long-term we should design for concurrency where possible (keeping thread safety in mind). That said, uncontrolled multi-threading is also a hazard – but the absence of any background processing suggests we might not reach performance targets. We should see at least networking running asynchronously, possibly AI decision making spread out, etc. If absolutely everything is funneling through one loop, know the limit and plan to refactor before hitting it.

Lack of Fault Tolerance / Error Handling: MMO runtime needs to be robust. Red flags here: code that assumes things will never fail (e.g., no try-catch around critical external calls like database or file access), or no timeout/retry for network messages. If a single exception can crash the server tick, that’s bad – it should catch and isolate failures when possible, or at least fail gracefully. So if you see code that, for example, calls an external service without error handling, or does casting and assumes success without validating data, mark that. Another example: not handling disconnects properly – e.g., continuing to send messages to a player object that’s already gone (null ref exceptions). These issues often show up as sporadic runtime errors that, if unguarded, can kill the whole process. In an MMO, one player’s bug should ideally not take down the whole server process. Defensive programming is key.

Over-Reliance on GC (or High Allocation Patterns): We’ve hammered on GC a lot; a specific anti-pattern is designing systems that churn a lot of short-lived objects (e.g., representing every network message as an object that gets parsed and discarded, rather than using reusable buffers). If a profiler snapshot shows a huge allocation rate (e.g., tens of MB per second of garbage), that is unsustainable – that’s a red flag that something needs pooling or a different approach. We might also consider the Large Object Heap (LOH) issue: allocating objects/arrays >85KB goes to LOH which is not compacted by Unity’s GC, causing fragmentation. If the code frequently allocates large byte arrays or such, that fragmentation can be a failure point over long uptime. So, red flag: lots of large allocations, or increasing fragmentation signs (mono memory footprint growing even when usage should stabilize).

Monolithic God Objects or Manager Spaghetti: If you find a single class doing far too much (e.g., GameManager that handles movement, combat, inventory, all in one), that’s a design smell. It’s not directly a performance issue but tends to correlate with harder-to-maintain code and higher risk of mistakes (and it can become a bottleneck since everything funnels through it). Similarly, if there is no clear separation of concerns (e.g., network code interwoven with game logic code), scaling out or changing one aspect becomes risky. We want modular systems (as per our technical design in Caelmor). So, seeing an “All-in-One Manager” is a soft red flag – maybe not an immediate failure, but a risk for future development and scaling (e.g., can’t multi-thread if one class holds all state). Breaking those apart improves clarity and may allow parallelism or easier load distribution later.

Magic Numbers and Tuning Knobs Missing: This is more of a maintenance flag: e.g., tick rate, max players, memory limits – if these are hardcoded all over or not present at all, that’s bad. We want to see central configuration for key parameters (tick rate, timeouts, etc.). If code uses arbitrary constants (like assuming a max of 100 players without explanation), it could fail if design changes. Not exactly a performance red flag, but a scalability one (what if we need 200 players? Does everything break?). So it’s flagged to ensure the system can adapt.

In summary, an MMO codebase should be scrutinized for anything that does not scale linearly, lacks limits, or can cause accumulating harm over time. We’ve identified: unbounded memory growth, quadratic algorithms, high GC churn, lingering references, single-thread chokepoints, and poor error isolation as prime red flags. When any of these are spotted, they must be addressed early – because in an MMO, small inefficiencies or leaks turn into massive problems under the weight of hundreds of players and continuous operation. Good engineering practices (profiling, load testing
forum.starbasegame.com
, code review against these patterns) are the safety net to catch red flags and convert them into action items (optimizations or redesigns) before they trigger failures in a live environment.

9. Output Usage Meta-Layer (Guidance for Documentation & Integration)

This technical brief contains various sections serving different purposes (training context, guardrails, prompts for code generation, etc.). Below, we clarify how each part should be used in the AI training and Codex deployment pipeline:

Section 1 (Terminology Normalization): This section is primarily research/reference-only. It defines key terms so that all team members (and AI assistants) use a consistent vocabulary. These definitions help ensure clarity in communication. However, they are not meant to be delivered verbatim to end-users or injected into Codex prompts. Rather, they inform the assistant’s understanding. In practice, these could be transformed into a glossary in internal documentation or simply used to align terminology internally. They do not need to appear in the final assistant instructions except possibly as a glossary reference.

Section 2 (Unity Compilation Pipeline): This is technical reference material. It provides detailed context on how Unity builds work (Mono vs IL2CPP). This would be useful in an internal knowledge base or a training document for engineers (or AI assistants) so they grasp build-time vs runtime behavior. However, it’s not a “guardrail” itself – it’s educational. For Codex or AI enforcement, you likely wouldn’t include all these details in the system prompt. Instead, section 2 can be summarized and placed in an internal technical manual for developers or a background context document for the AI. Its content ensures that if someone (or an AI) asks “why is IL2CPP used?” or “what does AOT mean?”, the answer is readily available. But it’s not a set of rules, so it’s mostly research-only for background understanding.

Section 3 (Myth Refutation): This section is a mix of explanation and philosophy, aimed at correcting misconceptions. It’s likely research/training material rather than guardrails. We want our AI assistants and team to understand that compilation isn’t the root cause of runtime issues. The content here could be used in an internal FAQ or even a blog post for educating junior developers. It’s not something you’d give as instructions to Codex for code generation. Thus, treat Section 3 as contextual knowledge – it influences how we prioritize optimizations (focus on code and architecture, not magical compiler fixes). It might be distilled into a guideline like “Don’t assume changing build settings will fix performance – profile and optimize code instead.” If anywhere, that distilled guidance could appear in an internal best-practices doc or a troubleshooting guide. But the full narrative form is for internal consumption (to shape mindset).

Section 4 (Runtime Cost Factors): This is descriptive analysis of performance categories. It’s quite detailed and educational. This should inform system design documentation and assistant understanding. For instance, an AI tasked with performance analysis could use this to reason about a problem (like “maybe it’s a GC issue or an interest management issue”). However, it’s not to be output to end-users directly. It’s too verbose for a system prompt and not a list of strict rules. So Section 4 is research-only / training material as well. It might be converted into a training module or internal wiki page on “Performance considerations for Caelmor MMO.” Downstream, if Codex had a mode to reason about performance, this knowledge would guide it. But it’s not something we paste into a guardrail doc, except possibly in summary form for context.

Section 5 (Runtime Architecture Ruleset): This section should be transformed into Markdown guardrails for developers and into system instructions for Codex. The bullet points of “must” and “must not” are explicit standards that code and design must follow. We would take these and include them in our “Coding Standards” document or Assistant System Message for the Systems Engineer AI. For example, when the AI Systems Engineer is activated, one of its system-level instructions will be: “All events must be unsubscribed on object destruction
stackoverflow.com
. Use object pooling for frequently instantiated objects
docs.unity3d.com
,” etc., essentially quoting or paraphrasing these rules. These could also be included in a public-facing “Unity MMO Best Practices” guide for our project, given to any engineer (human or AI). In short, Section 5’s content is directly actionable and should be integrated into both human-facing guidelines (project wiki, code review checklist) and AI guardrails. The language is already in a proper format (imperative must/must-not), which is ideal for a rules document or system prompt. Each bullet can be a separate rule entry in the guardrail list used by Codex.

Section 6 (Compilation Choices Scenarios): This is partly advisory and partly reference. It doesn’t contain strict rules; it discusses when to use IL2CPP vs Mono. This likely belongs in an internal technical decision record or knowledge base rather than in the live coding standard. Possibly, one could extract a short rule like “Use IL2CPP for final builds on all platforms for performance and security
docs.unity3d.com
 (except modding-friendly PC builds, which remain on Mono – if applicable).” If that decision is firm, it could be a line in the coding standards (“Builds must use IL2CPP unless a specific exception is approved”). Otherwise, Section 6 is mostly for human understanding and planning. It should be documented in our engine configuration guidelines. For Codex, we might not feed all this context in real-time; instead, we ensure the person setting up builds knows it. So usage: likely put this content into an internal document titled “Mono vs IL2CPP Decision Matrix” and not into the system prompt. The AI doesn’t typically choose the build backend (that’s a human build setting), so it’s more for engineers. Thus, Section 6 is reference, not a direct guardrail, except any rule we extract about defaulting to IL2CPP.

Section 7 (Codex Guardrail Instructions): This section is explicitly meant to become Codex system instructions. The bullet points here (written from an enforcement perspective) should be included in the system prompt given to the Codex model when it’s writing code for our project. They are phrased as commands to the AI (“must do this”, “must not do that”), which is exactly how OpenAI’s Codex can be guided. We will incorporate these into the master prompt for the Systems Engineer assistant. Additionally, they can be part of our AI development policy documentation – basically, these are the AI-specific version of the coding standards, ensuring the AI’s output doesn’t violate performance rules. In practice, one might merge Section 5 and Section 7, but Section 7 is more directly targeted at the AI generator itself. We should maintain these as a separate set of system-level guardrail rules. They will be included in the Markdown guardrails file for Codex. In short: Section 7 is high-priority for direct integration into the AI’s enforced guidelines.

Section 8 (Red Flags): This is somewhat like Section 4 – explanatory and meant for human/AI awareness – but it can also be actionable as a checklist for code reviews and automated analysis. We likely want to use this in two ways: (1) Internally, give this to developers and testers so they know what to watch out for (could be a page “Common MMO Anti-Patterns” on the wiki). (2) For AI, we could integrate this knowledge into a static analysis tool or an AI QA assistant. Possibly we will have an assistant that reviews code for performance issues; this list would be its reference of what to catch. It’s not exactly instructions to refrain (the guardrails already tell Codex not to do these things). It’s more about recognizing if they appear. So, Section 8’s content is research/analysis rather than generation rules. I would not put the entire narrative into a system prompt, but I would extract key points into an automated code review rule set. For example, one could formulate: “If the code contains nested loops over players without filtering, flag it,” “If a method allocates > X memory, flag it,” etc. That could be implemented in static analysis or an AI code reviewer role. So, the usage meta-layer: treat section 8 as the basis for Code Review Guidelines (for humans and AI reviewers). It complements sections 5 and 7 by focusing on detecting problems, whereas 5/7 focus on writing correct code initially.

Section 9 (Meta-Layer Guidance): This very section (9) is for internal planning and is not part of the technical standards themselves. It’s addressed to the team organizing how to use this document. So it doesn’t go to Codex or into any guardrail except perhaps as internal notes. Essentially, it’s served its purpose when we identify how to disseminate each part of the brief. After that, it’s not needed in the final documentation.
